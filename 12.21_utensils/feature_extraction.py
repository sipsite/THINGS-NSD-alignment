import os
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as T
import numpy as np
from torch.utils.data import DataLoader, TensorDataset
from tqdm import tqdm

# ================= é…ç½®åŒºåŸŸ =================
# æŒ‡å®š 48GB æ˜¾å­˜çš„é‚£å¼ å¡
os.environ["CUDA_VISIBLE_DEVICES"] = "2" 
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# æ‰¹å¤„ç†å¤§å° (48GB æ˜¾å­˜å¯ä»¥å¼€åˆ° 512 ç”šè‡³æ›´é«˜ï¼Œè¿™é‡Œç”¨ 512 å¾ˆç¨³)
BATCH_SIZE = 512
NUM_WORKERS = 16 # DataLoader çš„ CPU è¿›ç¨‹æ•°

# ================= æ¨¡å‹åŒ…è£…ç±» =================
class AllInOneExtractor(nn.Module):
    def __init__(self):
        super().__init__()
        print(f"ğŸš€ Loading models to {DEVICE}...")
        
        # 1. AlexNet (ç”¨äº Alex2, Alex5)
        # weights='DEFAULT' ç­‰åŒäº pretrained=True
        self.alexnet = models.alexnet(weights='DEFAULT').features.eval()
        
        # 2. Inception V3 (éœ€è¦è¾“å…¥ 299x299)
        self.inception = models.inception_v3(weights='DEFAULT', transform_input=False).eval()
        # Inception åœ¨ eval æ¨¡å¼ä¸‹ç›´æ¥è¾“å‡º logitsï¼Œæˆ‘ä»¬éœ€è¦æå–ç‰¹å¾å¯èƒ½éœ€è¦ hookï¼Œ
        # ä½†é€šå¸¸å­¦æœ¯ç•Œç›´æ¥ç”¨å®ƒçš„è¾“å‡ºå±‚ä½œä¸º embeddingï¼Œæˆ–è€… avgpool å±‚ã€‚
        # è¿™é‡Œä¸ºäº†é€šç”¨æ€§ï¼Œæˆ‘ä»¬å–æœ€åçš„è¾“å‡º (fc å‰çš„ä¸€å±‚é€šå¸¸æ•ˆæœæœ€å¥½ï¼Œä½† torchvision æ¥å£é»˜è®¤ç»™ logits)
        # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å– fc å±‚çš„è¾“å…¥ã€‚Inception forward ç¨å¾®å¤æ‚ï¼Œæˆ‘ä»¬åªç”¨å…¶ forward é€»è¾‘
        self.inception.fc = nn.Identity() # æ›¿æ¢æ‰åˆ†ç±»å¤´ï¼Œç›´æ¥è¾“å‡º 2048 ç»´ç‰¹å¾
        
        # 3. EfficientNet-B1
        self.effnet = models.efficientnet_b1(weights='DEFAULT')
        self.effnet.classifier = nn.Identity() # æ›¿æ¢åˆ†ç±»å¤´
        self.effnet.eval()
        
        # 4. SwAV (ResNet50 based)
        # SwAV æ˜¯æ— ç›‘ç£è®­ç»ƒçš„ ResNet50
        print("   Loading SwAV from torch.hub...")
        self.swav = torch.hub.load('facebookresearch/swav:main', 'resnet50')
        self.swav.fc = nn.Identity()
        self.swav.eval()

        # å®šä¹‰é¢„å¤„ç†
        self.normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        
        # å®šä¹‰ GPU ä¸Šçš„ Resize æ“ä½œ (æé€Ÿ)
        self.resize_224 = T.Resize((224, 224), antialias=True)
        self.resize_299 = T.Resize((299, 299), antialias=True) # Inceptionä¸“ç”¨

    def forward(self, x_uint8):
        """
        è¾“å…¥: (B, 3, H, W) uint8 Tensor [0-255]
        è¾“å‡º: å­—å…¸ {'alex2': ..., 'incep': ...}
        """
        results = {}
        
        # 1. å½’ä¸€åŒ–: uint8 [0-255] -> float [0-1] -> Normalize
        x = x_uint8.float() / 255.0
        x = self.normalize(x)
        
        # --- åˆ†æµ A: 224x224 (AlexNet, Eff, SwAV) ---
        x_224 = self.resize_224(x)
        
        # AlexNet (2 & 5)
        # AlexNet features ç»“æ„:
        # [0]Conv1 [1]ReLU [2]Pool [3]Conv2 [4]ReLU (Alex2) ... [10]Conv5 [11]ReLU (Alex5)
        with torch.no_grad():
            feat = self.alexnet[:5](x_224)
            results['alex2'] = feat.flatten(start_dim=1).cpu().numpy()
            
            feat = self.alexnet[:12](x_224)
            results['alex5'] = feat.flatten(start_dim=1).cpu().numpy()
            
            # EfficientNet
            results['eff'] = self.effnet(x_224).cpu().numpy()
            
            # SwAV
            results['swav'] = self.swav(x_224).cpu().numpy()

        # --- åˆ†æµ B: 299x299 (Inception) ---
        x_299 = self.resize_299(x)
        with torch.no_grad():
            results['incep'] = self.inception(x_299).cpu().numpy()
            
        return results

# ================= æå–å·¥å…·å‡½æ•° =================
def extract_all_features(image_array, model, desc="Extracting"):
    """
    image_array: numpy array (N, H, W, 3) uint8
    """
    # è½¬æ¢ä¸º TensorDatasetï¼Œåˆ©ç”¨ DataLoader çš„å¤šè¿›ç¨‹é¢„å–
    # è¿™é‡Œçš„ Tensor æ˜¯ CPU ä¸Šçš„ï¼ŒDataLoader è´Ÿè´£æ¬è¿
    # æ³¨æ„ï¼šä¸ºäº†èŠ‚çœæ˜¾å­˜ï¼Œæˆ‘ä»¬ä¼ å…¥ DataLoader çš„æ˜¯ permute åçš„å¼•ç”¨
    
    # è¿™ä¸€æ­¥å¾ˆå¿«ï¼Œå› ä¸ºåªæ˜¯ view å˜æ¢
    tensor_data = torch.from_numpy(image_array).permute(0, 3, 1, 2) # (N, 3, H, W)
    dataset = TensorDataset(tensor_data)
    
    loader = DataLoader(
        dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False, 
        num_workers=NUM_WORKERS,
        pin_memory=True # åŠ é€Ÿ CPU -> GPU ä¼ è¾“
    )
    
    # å®¹å™¨åˆå§‹åŒ–
    features = {
        'alex2': [], 'alex5': [], 'incep': [], 'eff': [], 'swav': []
    }
    
    model.eval()
    with torch.no_grad():
        for batch in tqdm(loader, desc=desc):
            imgs = batch[0].to(DEVICE, non_blocking=True) # (B, 3, H, W)
            
            # å‰å‘ä¼ æ’­
            batch_feats = model(imgs)
            
            # æ”¶é›†ç»“æœ
            for k, v in batch_feats.items():
                features[k].append(v)
    
    # åˆå¹¶ List ä¸º Numpy Array
    print(f"Concatenating features for {desc}...")
    final_dict = {}
    for k, v_list in features.items():
        final_dict[k] = np.concatenate(v_list, axis=0)
        print(f"  -> {k}: shape {final_dict[k].shape}")
        
    return final_dict

# ================= ä¸»æµç¨‹ =================
if __name__ == "__main__":
    # 1. è·¯å¾„é…ç½®
    base_path = "/home/ysunem/12.21/THINGS&NSD_code_ver2/"
    things_path = os.path.join(base_path, "things_img.npy")
    nsd_path = os.path.join(base_path, "nsd_img.npy")
    
    output_dir = "/home/ysunem/12.21/THINGS&NSD_code_ver2/features/"
    os.makedirs(output_dir, exist_ok=True)
    
    # 2. åˆå§‹åŒ–æ¨¡å‹ (ä¸€æ¬¡æ€§åŠ è½½åˆ° 48G æ˜¾å­˜)
    extractor = AllInOneExtractor().to(DEVICE)
    
    # 3. å¤„ç† Things æ•°æ®
    if os.path.exists(things_path):
        print(f"ğŸ“¥ Loading Things images from {things_path}...")
        things_img = np.load(things_path) # (16k, H, W, 3) uint8
        
        feats_things = extract_all_features(things_img, extractor, desc="Things")
        
        # ä¿å­˜
        save_path = os.path.join(output_dir, "feat_things.npy")
        np.save(save_path, feats_things)
        print(f"âœ… Saved Things features to {save_path}")
        
        # é‡Šæ”¾å†…å­˜
        del things_img, feats_things
    else:
        print("âš ï¸ Things images not found.")

    # 4. å¤„ç† NSD æ•°æ®
    if os.path.exists(nsd_path):
        print(f"ğŸ“¥ Loading NSD images from {nsd_path}...")
        nsd_img = np.load(nsd_path) # (73k, H, W, 3) uint8
        
        feats_nsd = extract_all_features(nsd_img, extractor, desc="NSD")
        
        # ä¿å­˜
        save_path = os.path.join(output_dir, "feat_nsd.npy")
        np.save(save_path, feats_nsd)
        print(f"âœ… Saved NSD features to {save_path}")
        
        del nsd_img, feats_nsd
    else:
        print("âš ï¸ NSD images not found.")
        
    print("ğŸ‰ All feature extraction completed.")