import json
import os
import datetime
import time

def get_current_time_info():
    now = datetime.datetime.now()
    standard_format = now.strftime("%m-%d_%H-%M-%S")
    return standard_format


def rearrange_json(input_path, output_path):
    """
    è¯»å–æ—§JSONï¼Œåˆå¹¶æ‰€æœ‰æ•°æ®ï¼Œæ ¹æ®æ–°é˜ˆå€¼é‡æ–°åˆ†ç»„ä¿å­˜
    """
    print(f"ğŸ“‚ Loading data from {input_path}...")
    
    if not os.path.exists(input_path):
        print(f"âŒ Error: File {input_path} not found.")
        return

    with open(input_path, 'r') as f:
        old_data = json.load(f)

    # 1. è·å–æ—§çš„ Metadata (ä¸ºäº†ä¿ç•™ weights ä¿¡æ¯)
    old_meta = old_data.get("metadata", {})
    weights = old_meta.get("weights", {})
    
    # 2. ã€å…³é”®æ­¥éª¤ã€‘æŠŠæ‰€æœ‰åˆ—è¡¨åˆå¹¶æˆä¸€ä¸ªå¤§ List
    # æ³¨æ„ï¼šæˆ‘ä»¬å‡è®¾ä¹‹å‰çš„ JSON é‡Œä¿ç•™äº† discardedã€‚
    # å¦‚æœä¹‹å‰ discarded æ˜¯ç©ºçš„ï¼Œé‚£æˆ‘ä»¬ä¹Ÿåªèƒ½åœ¨ç°æœ‰çš„ high/medium é‡Œé‡æ’ã€‚
    all_items = []
    all_items.extend(old_data.get("high_confidence_group", []))
    all_items.extend(old_data.get("medium_confidence_group", []))
    all_items.extend(old_data.get("discarded", []))
    # all_items.extend(old_data.get("group0", []))
    # all_items.extend(old_data.get("group1", []))
    # all_items.extend(old_data.get("group2", []))
    
    total_count = len(all_items)
    print(f"ğŸ“Š Total items loaded: {total_count}")

    t = [0.55, 0.45, 0.38]

    # 3. åˆå§‹åŒ–æ–°çš„å®¹å™¨
    new_output = {
        "metadata": {
            "total_queries": total_count,
            "thresholds" : t,
            "weights": weights, # ç»§æ‰¿ä¹‹å‰çš„æƒé‡è®¾ç½®
            "size_of_each_group": [0, 0, 0, 0]
        },
        "group0": [],  
        "group1": [], 
        "group2": [],
        "discarded": []        
    }

    # 4. ã€é‡ç­›ã€‘ä¸€ä¸ªä¸ªæ‘˜å‡ºæ¥
    seen_things = set()
    seen_nsd = set()
    for item in all_items:
        score = item["score_final"]
        if item["things_id"] in seen_things:
            continue
        if item["nsd_id"] in seen_nsd:
            continue
        if score >= t[2]: 
            seen_things.add(item["things_id"])
            seen_nsd.add(item["nsd_id"])
        if score >= t[0]:
            new_output["group0"].append(item)
            new_output["metadata"]["size_of_each_group"][0] += 1
        elif score >= t[1]:
            new_output["group1"].append(item)
            new_output["metadata"]["size_of_each_group"][1] += 1
        elif score >= t[2]:
            new_output["group2"].append(item)
            new_output["metadata"]["size_of_each_group"][2] += 1
    print("seen nsd : ", len(seen_nsd))
    print("seen things : ", len(seen_things))
    allow_duplicate = 1
    if allow_duplicate:
        for item in all_items:
            score = item["score_final"]
            if item["things_id"] in seen_things:
                continue
            if score >= t[2]: 
                seen_things.add(item["things_id"])
                seen_nsd.add(item["nsd_id"])
            if score >= t[0]:
                new_output["group0"].append(item)
                new_output["metadata"]["size_of_each_group"][0] += 1
            elif score >= t[1]:
                new_output["group1"].append(item)
                new_output["metadata"]["size_of_each_group"][1] += 1
            elif score >= t[2]:
                new_output["group2"].append(item)
                new_output["metadata"]["size_of_each_group"][2] += 1
    print("After allowing duplicate:")
    print("seen nsd : ", len(seen_nsd))
    print("seen things : ", len(seen_things))
    # 5. ä¿å­˜ç»“æœ
    with open(output_path, 'w') as f:
        json.dump(new_output, f, indent=4)

    print(f"âœ… Done! Saved to {output_path}")
    print("count : ", new_output["metadata"]["size_of_each_group"])

if __name__ == "__main__":
    # è¾“å…¥æ–‡ä»¶
    input_file = "retrieval_a2_t52.json"
    
    # è¾“å‡ºæ–‡ä»¶ 
    output_file = f"retrieval_rearranged_{get_current_time_info()}.json"
    
    rearrange_json(input_file, output_file)